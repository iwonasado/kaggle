{
 "metadata": {
  "name": "bulldozers"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import types\n",
      "import dateutil\n",
      "import datetime\n",
      "from dateutil import tz\n",
      "from multiprocessing import Pool\n",
      "import os, sys\n",
      "import random\n",
      "import pickle\n",
      "import pytz\n",
      "from pytz import timezone\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn import cross_validation\n",
      "import traceback\n",
      "\n",
      "na_values = [\"MISSING\", \"HIDDEN\"]\n",
      "\n",
      "def flatten(df, column_to_flatten, column_to_sort_flattening=None, index_to_ignore=None, max_number_to_flatten=None, prefix=\"\"):\n",
      "    grouped = df.groupby(column_to_flatten)\n",
      "    groups = []\n",
      "    i = 0\n",
      "    for name, group in grouped:\n",
      "        d = {column_to_flatten:name}\n",
      "        if column_to_sort_flattening is not None:\n",
      "            group = group.sort_index(by=column_to_sort_flattening, ascending=False)\n",
      "        if max_number_to_flatten is None:\n",
      "            max_number_to_flatten = len(group.values)\n",
      "        for k, (ix,row) in enumerate(group.iterrows()):\n",
      "            if index_to_ignore is not None and index_to_ignore == ix:\n",
      "                continue\n",
      "            prefix1 = k\n",
      "            if k == 0:\n",
      "                prefix1 = \"first\"\n",
      "            if k == len(group.values)-1:\n",
      "                prefix1 = \"last\"\n",
      "            for j, val in enumerate(row):\n",
      "                if group.columns[j] != column_to_flatten:\n",
      "                    d[\"{0}{1}_{2}\".format(prefix, prefix1, group.columns[j])] = val\n",
      "            if k > max_number_to_flatten:\n",
      "                break\n",
      "        groups.append(d)\n",
      "        i += 1\n",
      "    tmp_df = pd.DataFrame(groups)\n",
      "    tmp_df.set_index(column_to_flatten, inplace=True, verify_integrity=True)\n",
      "    return tmp_df\n",
      "\n",
      "def parse_date_time(val):\n",
      "    if str(val).lower().strip() not in na_values and str(val).lower().strip() != \"nan\":\n",
      "        #'2012-11-12 17:30:00+00:00\n",
      "        try:\n",
      "            datetime_obj = dateutil.parser.parse(val)\n",
      "            datetime_obj = datetime_obj.replace(tzinfo=timezone('UTC'))\n",
      "            datetime_obj = datetime_obj.astimezone(timezone('UTC'))\n",
      "            return datetime_obj\n",
      "        except ValueError as e:\n",
      "#            print e\n",
      "            return np.nan\n",
      "    else:\n",
      "        return np.nan\n",
      "#        return datetime.strptime(val, \"%Y-%m-%dT%H:%M:%S\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "store = pd.HDFStore('bulldozers.h5')\n",
      "store_filename = 'bulldozers.h5'\n",
      "data_prefix = '/Users/jostheim/workspace/kaggle/data/bulldozers/'\n",
      "df = pd.read_csv(\"{0}{1}\".format(data_prefix, \"train.csv\"), index_col=0, parse_dates=[9], date_parser=parse_date_time)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_sales_dates = np.unique(df['saledate'])\n",
      "unique_locations = np.unique(df['state'])\n",
      "i = 0\n",
      "for sale_date in unique_sales_dates:\n",
      "    per_sale_df = df[df['saledate'] == sale_date]\n",
      "    if len(np.unique(per_sale_df['state'])) > 1:\n",
      "        print \"uhoh\", len(np.unique(per_sale_df['state']))\n",
      "    flattened_df = None\n",
      "    for ix, row in per_sale_df.iterrows():\n",
      "        t_df = flatten(per_sale_df, 'saledate', 'YearMade', index_to_ignore=ix)\n",
      "        t_df['SalesID'] = ix\n",
      "        t_df.set_index('SalesID', inplace=True, verify_integrity=True)\n",
      "        if flattened_df is None:\n",
      "            flattened_df = t_df\n",
      "        else:\n",
      "            flattened_df = flattened_df.append(t_df)\n",
      "    print flattened_df\n",
      "    df = df.join(flattened_df)\n",
      "    i += 1\n",
      "    if i > 2:\n",
      "        break\n",
      "print df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}